{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "print(nltk_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05, random_state =100)\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95949"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'bright', 'sign', 'is', 'that', 'a', 'growing', 'number', 'of', 'women']\n",
      "12106\n"
     ]
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "print(tokens[:10])\n",
    "# vocabulary\n",
    "V = list(set(tokens))\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['ADP', 'X', 'NUM', 'ADV', 'PRON', 'ADJ', 'PRT', 'DET', '.', 'CONJ', 'NOUN', 'VERB']\n"
     ]
    }
   ],
   "source": [
    "# number of tags\n",
    "T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "print(len(T))\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag):\n",
    "    tag_list = [pair for pair in train_tagged_words if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag/count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1/count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADP</th>\n",
       "      <th>X</th>\n",
       "      <th>NUM</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>DET</th>\n",
       "      <th>.</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.017492</td>\n",
       "      <td>0.034984</td>\n",
       "      <td>0.061910</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>0.069119</td>\n",
       "      <td>0.107389</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.323969</td>\n",
       "      <td>0.039754</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.321213</td>\n",
       "      <td>0.008481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.144898</td>\n",
       "      <td>0.074433</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.055705</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.184891</td>\n",
       "      <td>0.055229</td>\n",
       "      <td>0.162831</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.062371</td>\n",
       "      <td>0.204571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.035056</td>\n",
       "      <td>0.211824</td>\n",
       "      <td>0.184195</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.033571</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.352347</td>\n",
       "      <td>0.016934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.119507</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>0.077230</td>\n",
       "      <td>0.015646</td>\n",
       "      <td>0.130160</td>\n",
       "      <td>0.014314</td>\n",
       "      <td>0.069907</td>\n",
       "      <td>0.135153</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>0.344541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.092720</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.072031</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.040613</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.211494</td>\n",
       "      <td>0.484291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.078624</td>\n",
       "      <td>0.020311</td>\n",
       "      <td>0.020803</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.063882</td>\n",
       "      <td>0.016052</td>\n",
       "      <td>0.700901</td>\n",
       "      <td>0.011794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.056102</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.083661</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.101050</td>\n",
       "      <td>0.043635</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.245735</td>\n",
       "      <td>0.405184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.009618</td>\n",
       "      <td>0.045323</td>\n",
       "      <td>0.021640</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.204977</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.637293</td>\n",
       "      <td>0.040394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.092206</td>\n",
       "      <td>0.026908</td>\n",
       "      <td>0.081353</td>\n",
       "      <td>0.052292</td>\n",
       "      <td>0.065208</td>\n",
       "      <td>0.043681</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.173558</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>0.058032</td>\n",
       "      <td>0.222531</td>\n",
       "      <td>0.088708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.053778</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.042188</td>\n",
       "      <td>0.053778</td>\n",
       "      <td>0.058414</td>\n",
       "      <td>0.118683</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.118683</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.350487</td>\n",
       "      <td>0.155308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.177058</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.043357</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.239951</td>\n",
       "      <td>0.042921</td>\n",
       "      <td>0.264280</td>\n",
       "      <td>0.146955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.091184</td>\n",
       "      <td>0.218438</td>\n",
       "      <td>0.022448</td>\n",
       "      <td>0.082050</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>0.065640</td>\n",
       "      <td>0.031427</td>\n",
       "      <td>0.133292</td>\n",
       "      <td>0.034291</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.111386</td>\n",
       "      <td>0.168744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADP         X       NUM       ADV      PRON       ADJ       PRT  \\\n",
       "ADP   0.017492  0.034984  0.061910  0.013357  0.069119  0.107389  0.001484   \n",
       "X     0.144898  0.074433  0.002857  0.025393  0.055705  0.016505  0.184891   \n",
       "NUM   0.035056  0.211824  0.184195  0.002674  0.001485  0.033571  0.026144   \n",
       "ADV   0.119507  0.023302  0.031624  0.077230  0.015646  0.130160  0.014314   \n",
       "PRON  0.023372  0.092720  0.007280  0.034100  0.007663  0.072031  0.012261   \n",
       "ADJ   0.078624  0.020311  0.020803  0.004914  0.000491  0.067158  0.010156   \n",
       "PRT   0.019357  0.013123  0.056102  0.010171  0.017717  0.083661  0.001969   \n",
       "DET   0.009618  0.045323  0.021640  0.012623  0.003727  0.204977  0.000240   \n",
       ".     0.092206  0.026908  0.081353  0.052292  0.065208  0.043681  0.002511   \n",
       "CONJ  0.053778  0.008809  0.042188  0.053778  0.058414  0.118683  0.003709   \n",
       "NOUN  0.177058  0.028868  0.009550  0.016813  0.004721  0.012165  0.043357   \n",
       "VERB  0.091184  0.218438  0.022448  0.082050  0.035916  0.065640  0.031427   \n",
       "\n",
       "           DET         .      CONJ      NOUN      VERB  \n",
       "ADP   0.323969  0.039754  0.000848  0.321213  0.008481  \n",
       "X     0.055229  0.162831  0.010316  0.062371  0.204571  \n",
       "NUM   0.003862  0.118835  0.013072  0.352347  0.016934  \n",
       "ADV   0.069907  0.135153  0.006991  0.031624  0.344541  \n",
       "PRON  0.009195  0.040613  0.004981  0.211494  0.484291  \n",
       "ADJ   0.004914  0.063882  0.016052  0.700901  0.011794  \n",
       "PRT   0.101050  0.043635  0.002297  0.245735  0.405184  \n",
       "DET   0.005771  0.017913  0.000481  0.637293  0.040394  \n",
       ".     0.173558  0.092923  0.058032  0.222531  0.088708  \n",
       "CONJ  0.118683  0.035698  0.000464  0.350487  0.155308  \n",
       "NOUN  0.013363  0.239951  0.042921  0.264280  0.146955  \n",
       "VERB  0.133292  0.034291  0.005186  0.111386  0.168744  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating t x t transition matrix of tags. Each column is t2, each row is t1. Thus M(i, j) represents P(tj given ti)\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)\n",
    "        \n",
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Vanilla_viterbi(words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            #emission_p = word_given_tag(words[key], tag)\n",
    "            #word_tag_df\n",
    "            emission_p = word_given_tag(words[key], tag)\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_set for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Investors', 'NOUN'), ('took', 'VERB'), ('advantage', 'NOUN'), ('of', 'ADP'), ('Tuesday', 'NOUN'), (\"'s\", 'PRT'), ('stock', 'NOUN'), ('rally', 'NOUN'), ('*-1', 'X'), ('to', 'PRT')]\n",
      "Wall time: 9min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagged_seq = Vanilla_viterbi(test_tagged_words)\n",
    "print(tagged_seq[:10])\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging. example from the NLTK book\n",
    "\n",
    "\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              \n",
    "    (r'.*ed$', 'VERB'),               \n",
    "    (r'.*es$', 'VERB'),               \n",
    "    (r'.*ly$', 'ADV'),              \n",
    "    (r'.*ble$', 'ADJ'),                \n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), \n",
    "    (r'(?<=[0-9])(?:st|nd|rd|th)$', 'NUM'), #ordinal Numbers\n",
    "    (r'.*', 'NOUN')                    \n",
    "]\n",
    "\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "def rulebased_tagging(test_words):\n",
    "    return regexp_tagger.tag([test_words])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Viterbi Heuristic\n",
    "\n",
    "def Viterbi_probabilistic(words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            #emission_p = word_given_tag(words[key], tag)\n",
    "            #word_tag_df\n",
    "            if(words[key] in V):\n",
    "                emission_p = word_given_tag(words[key], tag)\n",
    "                state_probability = emission_p * transition_p\n",
    "            else:\n",
    "                state_probability = transition_p\n",
    "                                   \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_rulebased(words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    for key, word in enumerate(words):\n",
    "    #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        state_probability = 0\n",
    "        rule_tag = \"\"\n",
    "        if words[key] in V:\n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "                # compute emission and state probabilities\n",
    "                emission_p = word_given_tag(words[key], tag)\n",
    "                state_probability = emission_p * transition_p\n",
    "                p.append(state_probability)\n",
    "            pmax = max(p)\n",
    "            state_max = T[p.index(pmax)]\n",
    "            state.append(state_max)\n",
    "            \n",
    "        else:\n",
    "            rule_tag=rulebased_tagging(words[key])\n",
    "            state.append(rule_tag)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9331499894224666\n",
      "Wall time: 8min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagged_seq1 = Viterbi_probabilistic(test_tagged_words)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq1, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9481700867357732\n",
      "Wall time: 8min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagged_seq2 = Viterbi_rulebased(test_tagged_words)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq2, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Viswas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Viswas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Viswas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import brown\n",
    "# nltk.download('brown')\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "\n",
    "import requests\n",
    "response = requests.get('https://cdn.upgrad.com/UpGrad/temp/9dca5f3b-53c3-47e1-86d5-5ec5dafad6f0/Test_sentences.txt')\n",
    "data = response.text\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentense = sent_tokenize(data)\n",
    "word_sample= word_tokenize(data)\n",
    "\n",
    "\n",
    "# calculating tags using nltk.pos_tags, tagset universal\n",
    "\n",
    "tagged_data=nltk.pos_tag(word_sample,tagset='universal')\n",
    "# tagged_data\n",
    "sample_sent =list([pair[0] for pair in tagged_data])\n",
    "sample_sent[:5]\n",
    "tagged_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'ADP'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN')]\n",
      "0.7624309392265194\n"
     ]
    }
   ],
   "source": [
    "# Original Vanilla Viterbi algorithm\n",
    "tagged_seq3 = Vanilla_viterbi(sample_sent)\n",
    "print(tagged_seq3[:5])\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq3, tagged_data) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq3)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN')]\n",
      "0.8674033149171271\n"
     ]
    }
   ],
   "source": [
    "# Modified viterbi using probablilistic algorithm\n",
    "tagged_seq4 = Viterbi_probabilistic(sample_sent)\n",
    "print(tagged_seq4[:5])\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq4, tagged_data) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq4)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN')]\n",
      "0.9281767955801105\n"
     ]
    }
   ],
   "source": [
    "# Modified viterbi using rule-based algorithm\n",
    "tagged_seq5 = Viterbi_rulebased(sample_sent)\n",
    "print(tagged_seq5[:5])\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq5, tagged_data) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq5)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
